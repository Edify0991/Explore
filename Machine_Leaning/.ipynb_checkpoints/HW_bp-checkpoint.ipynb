{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62bbcc5",
   "metadata": {},
   "source": [
    "## BP神经网络\n",
    "\n",
    "根据BP神经网络原理，实现简单的BP神经网络(64, 100, 10)，并绘制网络结构简图和标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import LabelBinarizer# 标签二值化\n",
    "from sklearn.model_selection import train_test_split # 切割数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()# 载入数据\n",
    "X = digits.data# 数据\n",
    "y = digits.target# 标签\n",
    "\n",
    "# 数据归一化\n",
    "X -= X.min()\n",
    "X /= X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e638dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):                                                                   \n",
    "    ret = np.zeros((len(x)))                                                      \n",
    "    for i in range(len(x)):                                                       \n",
    "        if x[i] >= 0:                                                             \n",
    "            ret[i] = 1.0 / (1 + np.exp(-x[i]))                                    \n",
    "        else:                                                                     \n",
    "            ret[i] = np.exp(x[i]) / (1 + np.exp(x[i]))                            \n",
    "    return ret                                                                    \n",
    "                                                                                  \n",
    "def dsigmoid(x):                                                                  \n",
    "    #print(x)                                                                     \n",
    "    return x * (1 - x)                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9708e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:                                                                                                                                                                                                \n",
    "    # 初始化网络                                                                                                                                                                                                         \n",
    "    def __init__(self, layers):  # (64,100,10)                                                                                                                                                                      \n",
    "        self.layers_num = len(layers)   #神经网络层数                                                                                                                                                                     \n",
    "        self.layers = layers                                                                                                                                                                                        \n",
    "        #除去输入层，其余层需要随机产生n个神经元的bias值，在（0，1）之间                                                                                                                                                                        \n",
    "        self.biases = [np.random.randn(y, 1) for y in layers[1: ]]  #randn的参数表示产生随机数数量的各维度大小，layers[1:]其中的1是因为从第二层开始才需要bias                                                                                         \n",
    "        #随机产生每条神经元连接线的权重值，在（0，1）之间                                                                                                                                                                                  \n",
    "        #zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。                                                                                                                                                    \n",
    "        #如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同，利用 * 号操作符，可以将元组解压为列表                                                                                                                                                       \n",
    "        #如a = [1,2,3] b = [4,5,6] zipped = zip(a,b) ： [(1, 4), (2, 5), (3, 6)]                                                                                                                                      \n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(layers[: -1], layers[1: ])]                                                                                                                           \n",
    "                                                                                                                                                                                                                    \n",
    "    def cost_derivative(self, output_activations, y):                                                                                                                                                               \n",
    "        return (output_activations - y)                                                                                                                                                                             \n",
    "                                                                                                                                                                                                                    \n",
    "    def backprop(self, x, y):                                                                                                                                                                                       \n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]                                                                                                                                                          \n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]                                                                                                                                                         \n",
    "        # 前向传输                                                                                                                                                                                                      \n",
    "        #每个数据是一个长64的array数组                                                                                                                                                                                         \n",
    "        activation = x                                                                                                                                                                                              \n",
    "        # 储存每层的神经元的值的矩阵，下面循环会 append 每层的神经元的值                                                                                                                                                                       \n",
    "        activations = [x]                                                                                                                                                                                           \n",
    "        # 储存每个未经过 sigmoid 计算的神经元的值                                                                                                                                                                                  \n",
    "        zs = []                                                                                                                                                                                                     \n",
    "        #print(self.biases)                                                                                                                                                                                         \n",
    "        for b, w in zip(self.biases, self.weights):                                                                                                                                                                 \n",
    "            #print(activation.ndim)                                                                                                                                                                                 \n",
    "            if b.ndim == 1:                                                                                                                                                                                         \n",
    "                b = b.reshape(1, len(b))                                                                                                                                                                            \n",
    "            if activation.ndim == 1:                                                                                                                                                                                \n",
    "                activation = activation.reshape(1, len(activation))                                                                                                                                                 \n",
    "            if w.shape[1] != activation.shape[0]:                                                                                                                                                                   \n",
    "                activation = activation.transpose()                                                                                                                                                                 \n",
    "            dot_res = np.dot(w, activation)                                                                                                                                                                         \n",
    "                                                                                                                                                                                                                    \n",
    "            z = dot_res + b                                                                                                                                                                                         \n",
    "            #print(z)                                                                                                                                                                                               \n",
    "            #print((np.dot(w, activation)).shape)                                                                                                                                                                   \n",
    "            #print(w.shape)                                                                                                                                                                                         \n",
    "            #print(z.shape)                                                                                                                                                                                         \n",
    "            zs.append(z)                                                                                                                                                                                            \n",
    "            activation = sigmoid(z)                                                                                                                                                                                 \n",
    "            #print(activation.shape)                                                                                                                                                                                \n",
    "            activations.append(activation)                                                                                                                                                                          \n",
    "                                                                                                                                                                                                                    \n",
    "                                                                                                                                                                                                                    \n",
    "        # 求 δ 的值                                                                                                                                                                                                    \n",
    "        #print(zs[-1])                                                                                                                                                                                              \n",
    "        delta = self.cost_derivative(activations[-1].reshape(-1), y) * dsigmoid(activations[-1].reshape(-1))                                                                                                        \n",
    "        delta = delta.reshape(len(delta), 1)                                                                                                                                                                        \n",
    "        nabla_b[-1] = delta                                                                                                                                                                                         \n",
    "                                                                                                                                                                                                                    \n",
    "        nabla_w[-1] = np.dot(delta.reshape(1, len(delta)).transpose(), activations[-2].reshape(1, len(activations[-2])))                                                                                            \n",
    "                                                                                                                                                                                                                    \n",
    "        #这里进行逆向遍历，比如当l为2时，zs[-l]为网络的倒数第二层                                                                                                                                                                           \n",
    "        for l in range(2, self.layers_num):                                                                                                                                                                         \n",
    "            activation = activations[-l]                                                                                                                                                                            \n",
    "            sp = dsigmoid(activation)                                                                                                                                                                               \n",
    "                                                                                                                                                                                                                    \n",
    "            delta = np.dot(self.weights[-l + 1].transpose(), delta) * sp.reshape(len(sp), 1)                                                                                                                        \n",
    "                                                                                                                                                                                                                    \n",
    "            nabla_b[-l] = delta                                                                                                                                                                                     \n",
    "                                                                                                                                                                                                                    \n",
    "            nabla_w[-l] = np.dot(delta.reshape(len(delta), 1), activations[-l - 1].reshape(1, len(activations[-l - 1])))                                                                                            \n",
    "        #print(nabla_w)                                                                                                                                                                                             \n",
    "        return (nabla_b, nabla_w)                                                                                                                                                                                   \n",
    "    def train(self, x_data, y_data, lr=0.3, epochs=10000):                                                                                                                                                          \n",
    "        accuracy = []  # 用来保存测试过程中的准确率                                                                                                                                                                              \n",
    "        loss = []  # 用来保存测试时产生的代价函数的值                                                                                                                                                                               \n",
    "        for n in range(epochs + 1):                                                                                                                                                                                 \n",
    "            # 更新权重                                                                                                                                                                                                  \n",
    "            # 根据 biases 和 weights 的行列数创建对应的全部元素值为 0 的空矩阵                                                                                                                                                            \n",
    "            nabla_b = [np.zeros(b.shape) for b in self.biases]                                                                                                                                                      \n",
    "            nabla_w = [np.zeros(w.shape) for w in self.weights]                                                                                                                                                     \n",
    "            for i in range(len(x_data)):                                                                                                                                                                            \n",
    "                # 根据样本中的每一个输入 x 的其输出 y，计算 w 和 b 的偏导数                                                                                                                                                                \n",
    "                x = x_data[i]                                                                                                                                                                                       \n",
    "                y = y_data[i]                                                                                                                                                                                       \n",
    "                #print(y)                                                                                                                                                                                           \n",
    "                delta_nabla_b, delta_nabla_w = self.backprop(x, y)                                                                                                                                                  \n",
    "                #print(delta_nabla_b)                                                                                                                                                                               \n",
    "                # 累加储存偏导值 delta_nabla_b 和 delta_nabla_w                                                                                                                                                             \n",
    "                #nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]                                                                                                                                    \n",
    "                #nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]                                                                                                                                    \n",
    "                self.weights = [w - lr * nw for w, nw in zip(self.weights, delta_nabla_w)]                                                                                                                          \n",
    "                self.biases = [b - lr * nb for b, nb in zip(self.biases, delta_nabla_b)]                                                                                                                            \n",
    "            print(n)                                                                                                                                                                                                \n",
    "            # 更新根据累加的偏导值更新 w 和 b，                       (这里因为用了小样本，所以 eta 要除于小样本的长度)                                                                                                                                \n",
    "                                                                                                                                                                                                                    \n",
    "                                                                                                                                                                                                                    \n",
    "            # 每训练200次预测，输出一次预测准确率                                                                                                                                                                                   \n",
    "            if n % 10 == 0 and n != 0:                                                                                                                                                                              \n",
    "                predictions = []                                                                                                                                                                                    \n",
    "                for j in range(X_test.shape[0]):                                                                                                                                                                    \n",
    "                    # 获取预测结果：返回与十个标签值逼近的距离，数值最大的选为本次的预测值                                                                                                                                                            \n",
    "                    output = self.predict(X_test[j])                                                                                                                                                                \n",
    "                    # 将最大的数值所对应的输出层神经元记为1，其余输出层神经元为0                                                                                                                                                                \n",
    "                    predictions.append(np.argmax(output))  # 获取预测结果                                                                                                                                                 \n",
    "                    sum = np.sum(np.square(self.cost_derivative(output, labels_test)))                                                                                                                              \n",
    "                #print(y_test)                                                                                                                                                                                      \n",
    "                acc = np.mean(np.equal(predictions, y_test))                                                                                                                                                        \n",
    "                #print(len(predictions))                                                                                                                                                                            \n",
    "                accuracy.append(acc)                                                                                                                                                                                \n",
    "                print(acc)                                                                                                                                                                                          \n",
    "                cost = sum / 2 / X_test.shape[0]                                                                                                                                                                    \n",
    "                #print(cost)                                                                                                                                                                                        \n",
    "                loss.append(cost)                                                                                                                                                                                   \n",
    "                # np.equal()：相同返回true，不同返回false                                                                                                                                                                     \n",
    "        return accuracy, loss                                                                                                                                                                                       \n",
    "                                                                                                                                                                                                                    \n",
    "    def predict(self, x):                                                                                                                                                                                           \n",
    "        # 计算输出层得到的结果                                                                                                                                                                                                \n",
    "        # argmax()返回的就是最                                                                                                                                                                                            \n",
    "        activation = x                                                                                                                                                                                              \n",
    "        for b, w in zip(self.biases, self.weights):                                                                                                                                                                 \n",
    "            if b.ndim == 1:                                                                                                                                                                                         \n",
    "                b = b.reshape(1, len(b))                                                                                                                                                                            \n",
    "            if activation.ndim == 1:                                                                                                                                                                                \n",
    "                activation = activation.reshape(1, len(activation))                                                                                                                                                 \n",
    "            if w.shape[1] != activation.shape[0]:                                                                                                                                                                   \n",
    "                activation = activation.transpose()                                                                                                                                                                 \n",
    "            dot_res = np.dot(w, activation)                                                                                                                                                                         \n",
    "                                                                                                                                                                                                                    \n",
    "            layer2 = dot_res + b                                                                                                                                                                                    \n",
    "            activation = sigmoid(layer2)                                                                                                                                                                            \n",
    "        #print(activation)                                                                                                                                                                                          \n",
    "        return activation                                                                                                                                                                                           \n",
    "                                                                                                                                                                                                                                                                                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d09c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork([64,100,10])#创建网络\n",
    " \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y) #分割数据\n",
    "\n",
    "labels_train = LabelBinarizer().fit_transform(y_train)#标签二值化\n",
    "labels_test = LabelBinarizer().fit_transform(y_test)#标签二值化\n",
    "\n",
    "epoch = 20000\n",
    "accuracy, loss = nn.train(X_train,labels_train,epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652cf570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练结果可视化\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(range(0, epoch, int(epoch/len(loss))), loss)\n",
    "plt.ylabel('loss')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(0, epoch, int(epoch/(len(accuracy)))), accuracy)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c86b561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a423d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e8cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e4db1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d21ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719bcd14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
